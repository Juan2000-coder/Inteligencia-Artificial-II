{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtwT9kJTp2kc"
      },
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "Dado el conjunto de puntos que puede descargar del [siguiente enlace](https://drive.google.com/file/d/1g8KNOJsaE3jzXob-ZsTE_PqYwuxJ05pg/export?format=txt), genere un modelo de regresión multicapa que permita aproximar la tendencia del dataset.\n",
        "\n",
        "![DiagramaElectrico](https://drive.google.com/uc?export=view&id=1a3zJAPE3DQi06LktoVoBlb91eaMHYkvv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRFhmvDzsjaO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5yhJoLJuji5"
      },
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Existe una base de datos llamada MNIST que contiene imágenes de dígitos manuscritos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "problema de clasificaciòn supervisado multiclase nominal porque depende de la forma y no de un orden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "YU_Y0oKYyeiR",
        "outputId": "72ea5ecf-2e9f-45d1-f037-d42b7e5bbbca"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Cargar el dataset MNIST\u001b[39;00m\n\u001b[1;32m      6\u001b[0m (X_train, y_train), (_, _) \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Cargar el dataset MNIST\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# Mostrar 15 ejemplos aleatorios\n",
        "r, c = 3, 5\n",
        "fig = plt.figure(figsize=(2*c, 2*r))\n",
        "for _r in range(r):\n",
        "    for _c in range(c):\n",
        "        ix = np.random.randint(0, len(X_train))\n",
        "        img = X_train[ix]\n",
        "        plt.subplot(r, c, _r*c + _c + 1)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(y_train[ix])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGwbXA6i0JZu"
      },
      "source": [
        "Normalice las imágenes del dataset y utilice la librería `scikitlearn` para crear un modelo que permita clasificar el dataset correctamente para indicar el valor representado en cada imagen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las operaciones que hay que hacer para preparar el dataset son:\n",
        "- Divisiòn del conjunto de datos en el set de entrenamiento y el de test\n",
        "- Se hace un reshape o reordenamiento de los datos y sanitizaciòn vieno los datos que sirven y los que no\n",
        "- Se normalizan los datos (se reescalan para que esten comprendidos en un intervalo deseable, como por ejemplo -1 a 1 o 0 y 1). Aca esta nuestra primer tarea que es la de investigar los distintos escaler de la libreria de scikit learn para ver cual es el mejor que podriamos utilizar. La normalización se hace sobre todos los datos de los dos conjuntos. Pero el escalador se entrena solamente con el set de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guQTQ2d-17Io"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEKNfsLq17bo"
      },
      "source": [
        "Puede utilizar el siguiente código para generar una matriz de confusión que permita observar el desempeño del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCN5xXl52QYW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "\n",
        "y_pred = evaluate(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Luego de que los datos están preparados se puede aplicar algún modelo para la clasificación de los datos, osea, para entrenar el modelo. Acá esta nuestra otra tarea, que es la de seleccionar el clasificador que vamos a utilizar.\n",
        "- La matriz de confusiòn es un método de comparación o evaluación de la exactitud del modelo en donde se ponen las predicciones con los valores reales y se comparan los verdaderos, los falsos (eso de los falsos positivos, los falsos negativos, los verdaderos positivos y los verdaderos negativos). EL mapa de calor es la visualización de los resultados de esa matriz utilizando colores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- SVM (support vector machine)\n",
        "- SVC (...clasfificator)\n",
        "- SVR (... regresor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- El concepto de lote (batch) no debe entrar necesariamente en todos los métodos de machine learning, siempre aparece en las redes neuronales sin embargo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-  El profe propuso un modelo que va a compartir y tiene un error conceptual que hay que descubrir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8zLhYor2s9J"
      },
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Descargue el código de [este repositorio](https://github.com/Jugarov/DinoGame), que contiene una reproducción del juego del dinosaurio de Google Chrome.\n",
        "\n",
        "**3.1.** Modifique las funciones del archivo `NeuralNetwork.py` para crear una red neuronal multicapa fully-connected con las entradas y salidas que precise necesarias de manera que permita que el dinosaurio pueda saltar los cactus y agacharse ante los pájaros.\n",
        "\n",
        "&emsp;&emsp;3.1.1. En la función `initialize` describa los valores iniciales de la matriz de pesos y bias que vaya a utilizar.\n",
        "\n",
        "&emsp;&emsp;3.1.2. En la función `think` tome como argumento de la función los parámetros que necesite como entrada de la red y procese los mismos para obtener un resultado a la salida de la red. **Recuerde modificar la línea que utiliza esta función en `main.py` (línea 151)**.\n",
        "\n",
        "&emsp;&emsp;3.1.3. En la función `act` defina qué función de activación utilizará para tomar una decisión sobre la siguiente acción del dinosaurio. Devuelva una etiqueta indicando dicha acción.\n",
        "\n",
        "**3.2** Modifique las funciones del archivo `Genetic.py` para que, al final de cada generación (cuando todos los dinosaurios colisionan) se actualicen los pesos y biases de las matrices de la red neuronal usando un algoritmo genético.\n",
        "\n",
        "La población será el número de dinosaurios que estén funcionando a la vez. Como función de evaluación, use la propiedad `score` de cada uno de los individuos.\n",
        "\n",
        "&emsp;&emsp;3.2.1. La función `updateNetwork` recibe un vector de elementos de la clase `Dinosaur`. Esta función debe encargarse de aplicar una función de selección a cada individuo, seleccionarlos, cruzar los valores de las matrices y aplicar un mecanismo de mutación para generar la nueva población. Una vez generada la nueva población, **sustituya la matriz de cada individuo del vector `poblacion` que se usa en la entrada por el elemento correspondiente de la población evolucionada**. Solo así se verá afectado el comportamiento de los dinosaurios en sucesivas iteraciones.\n",
        "\n",
        "&emsp;&emsp;3.2.2. La función `select_fittest` recibe el mismo vector que la función `updateNetwork` y debe ser capaz de analizar la propiedad `score` de cada individuo para formar parejas. Se sugiere que esta función devuelva como resultado los índices de los elementos seleccionados.\n",
        "\n",
        "&emsp;&emsp;3.2.3. La función `evolve` recibe como argumento los dos elementos de la clase `Dinosaur` que han sido seleccionados por la clase anterior y les aplica el mecanismo de cruce y mutación de su elección. Puede incorporar un mecanismo de elitismo si lo desea.\n",
        "\n",
        "El objetivo del ejercicio es lograr que alguno de los dinosaurios alcance una puntuación de por lo menos 1000 puntos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiQOgftLDYY5"
      },
      "source": [
        "# Ejercicio 4\n",
        "\n",
        "El juego usado en el ejercicio anterior permite capturar imágenes y guardarlas en el directorio correspondiente a la tecla que se estuviera pulsando al momento de la captura para usarlo como etiqueta de los datos. Cree una base de datos, sanitarícelos, normalícelos y utilícelos para crear un modelo de red neuronal usando la librería *Tensorflow*. En el archivo `BuildTensorflowModel.py` encontrará las herramientas necesarias para realizar este proceso.\n",
        "\n",
        "Una vez creado el modelo, corra el juego en el modo de ejecución *automático con modelo* (modo 'a' desde el menú principal del juego) y verifique que el dinosaurio sea capaz de alcanzar nuevamente una puntuación de 1000 puntos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
